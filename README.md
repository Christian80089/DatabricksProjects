# Databricks ETL Portfolio

Data Engineering projects showcasing PySpark, Delta Lake, and Unity Catalog.

## ğŸ““ Notebooks

### Simple ETL Pipeline

| Notebook | Description | View |
|----------|-------------|------|
| **ETL Pipeline** | Extract â†’ Transform â†’ Load with Unity Catalog | [ğŸ““ Open Project](https://gist.github.com/Christian80089/3351d92cf31c7e17c2968324e94a32cb) |

## ğŸ¤– AI-Augmented Development Approach (100% Transparency)

### Why I Use AI in My Workflow

I leverage AI as a **productivity multiplier** to accelerate standard processes and automate repetitive tasks, not as a replacement for technical expertise. Think of it this way:

> **AI is like a Formula 1 engine**:  
> â€¢ Without a skilled driver â†’ crashes at the first turn  
> â€¢ With an expert driver â†’ wins the race  
> 
> The engine provides **speed**, the driver provides **direction, strategy, and control**.

### How I Use AI

**For Code Generation**:
- âœ… **I design** the architecture and data flow
- âœ… **I define** business logic and transformation rules
- âœ… **AI accelerates** boilerplate code and standard patterns
- âœ… **I review, optimize, and validate** every line

**Example Workflow**:
My Input:
"Create ETL pipeline: CSV â†’ deduplicate â†’ standardize â†’ partition by year/month â†’ Z-ORDER by category/region"

AI Output:
PySpark code with transformations

My Role:
âœ“ Validate logic correctness
âœ“ Optimize for performance
âœ“ Add error handling
âœ“ Ensure data quality
âœ“ Test edge cases

### What AI Cannot Replace

| What AI Does | What I Do |
|--------------|-----------|
| Generate code syntax | Design data architecture |
| Suggest standard patterns | Make strategic technical decisions |
| Automate documentation | Understand business requirements |
| Speed up repetitive tasks | Debug complex issues |
| Provide boilerplate | Optimize for specific use cases |

### The Value Proposition

**Traditional Approach**: 8 hours to write + document ETL pipeline  
**AI-Augmented Approach**: 2 hours with AI assistance, 6 hours freed for:
- Advanced optimization
- Data quality frameworks
- Testing and validation
- Architecture design
- Problem-solving complex edge cases

**Result**: More time for high-value work, faster delivery, better quality.

<p align="center">
  <i>Building smarter, not harder â€” with AI as a co-pilot, not a replacement</i>
</p>

## ğŸ› ï¸ Technologies

- Python & PySpark
- Delta Lake
- Unity Catalog
- Databricks

## ğŸ“§ Contact

Email: christiandelprete01@gmail.com
LinkedIn: [Christian Del Prete](www.linkedin.com/in/christian-del-prete)
